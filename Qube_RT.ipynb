{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "try :\n",
        "  from google.colab import drive\n",
        "  from google.colab import files\n",
        "  drive.mount('/content/drive')\n",
        "  PATH_GC = '/content/drive/My Drive' \n",
        "except Exception:\n",
        "  print(\"Vous n'êtes pas sur Google Colab, vous êtes en local, assurez-vous d'avoir ajouter le Path du dossier Colab_sources\")\n",
        "  PATH_GC = './'#Emplacement du dossier /Colab_sources"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0w37Ew3wgnMO",
        "outputId": "1b8da046-8f75-444a-b536-f6081d0f8503"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "eGoh1WaygMFU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "whTuYoITgMFb"
      },
      "outputs": [],
      "source": [
        "X_train = pd.read_csv(PATH_GC+'/Challenge/X_train.csv', index_col=0, sep=',')\n",
        "X_train.columns.name = 'date'\n",
        "\n",
        "Y_train = pd.read_csv(PATH_GC+'/Challenge/Y_train.csv', index_col=0, sep=',')\n",
        "Y_train.columns.name = 'date'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EGfvDOk6gMFc",
        "outputId": "60180e14-5f1a-4884-ecf3-8e97eddcdc02"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:1: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n"
          ]
        }
      ],
      "source": [
        "X_train_reshape = pd.concat([ X_train.T.shift(i+1).stack(dropna=False) for i in range(250) ], 1).dropna()\n",
        "X_train_reshape.columns = pd.Index(range(1,251), name='timeLag')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_reshape\n"
      ],
      "metadata": {
        "id": "pVeUH7JVhDnm",
        "outputId": "24c9313d-42f0-407b-c8dc-72418afb0074",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "timeLag             1         2         3         4         5         6    \\\n",
              "date stocksID                                                               \n",
              "250  0         0.000103  0.012387  0.011243  0.002595 -0.008509 -0.002711   \n",
              "     1        -0.000982  0.003932  0.000050  0.001616 -0.003902 -0.001686   \n",
              "     2         0.009301  0.003914  0.004995  0.001539  0.001452  0.002809   \n",
              "     3         0.006515 -0.006553  0.009464  0.005204  0.004227 -0.005438   \n",
              "     4        -0.006223  0.005415  0.014643  0.005195  0.004489  0.002695   \n",
              "...                 ...       ...       ...       ...       ...       ...   \n",
              "753  45        0.009786 -0.001861  0.012294 -0.023981  0.004069  0.000148   \n",
              "     46       -0.008842  0.003698  0.005138 -0.004295 -0.010509  0.010230   \n",
              "     47       -0.008607  0.006122 -0.007828 -0.008224  0.011357 -0.012855   \n",
              "     48       -0.007519  0.001956  0.001903  0.001535  0.000695  0.004107   \n",
              "     49       -0.002816 -0.002696 -0.007145 -0.001814  0.004331  0.005457   \n",
              "\n",
              "timeLag             7         8         9         10   ...       241  \\\n",
              "date stocksID                                          ...             \n",
              "250  0         0.008934  0.006571 -0.018546 -0.008353  ...  0.009119   \n",
              "     1         0.008810  0.001585 -0.000745 -0.002155  ...  0.001664   \n",
              "     2         0.005177 -0.006942 -0.013340 -0.008071  ...  0.007416   \n",
              "     3         0.008861  0.004025 -0.012432 -0.006100  ...  0.003807   \n",
              "     4         0.007609  0.011437 -0.004804  0.039274  ...  0.014404   \n",
              "...                 ...       ...       ...       ...  ...       ...   \n",
              "753  45       -0.062300  0.040002 -0.003475 -0.016284  ...  0.003808   \n",
              "     46        0.006846  0.017514 -0.010796 -0.026356  ... -0.012077   \n",
              "     47        0.000346 -0.016681  0.008247 -0.002723  ...  0.007291   \n",
              "     48       -0.011879  0.000526  0.003178 -0.010654  ...  0.010960   \n",
              "     49        0.000633 -0.005819  0.007592 -0.002003  ... -0.024003   \n",
              "\n",
              "timeLag             242       243       244       245       246       247  \\\n",
              "date stocksID                                                               \n",
              "250  0        -0.008451  0.007120 -0.011745  0.009092 -0.005110 -0.016676   \n",
              "     1        -0.002747  0.009994 -0.001293  0.012912 -0.004055 -0.006820   \n",
              "     2         0.001600  0.007640 -0.000637 -0.001353 -0.009522 -0.003425   \n",
              "     3        -0.010636  0.012446 -0.011980  0.002485 -0.017981 -0.010899   \n",
              "     4        -0.005255 -0.008182 -0.004614  0.007082  0.007872 -0.003515   \n",
              "...                 ...       ...       ...       ...       ...       ...   \n",
              "753  45       -0.003027  0.002522 -0.006594 -0.000489  0.054751 -0.012180   \n",
              "     46       -0.002215  0.027569  0.021476  0.003874 -0.001690  0.012346   \n",
              "     47        0.000369  0.000962 -0.005902  0.001067  0.013055  0.015432   \n",
              "     48       -0.012003 -0.001969  0.030976 -0.000712  0.009795 -0.006842   \n",
              "     49        0.001416  0.003348 -0.003685 -0.002267 -0.006733  0.000575   \n",
              "\n",
              "timeLag             248       249       250  \n",
              "date stocksID                                \n",
              "250  0        -0.010776 -0.013002 -0.018647  \n",
              "     1         0.012173 -0.022280 -0.008254  \n",
              "     2        -0.006044 -0.013629 -0.008404  \n",
              "     3        -0.008568 -0.006981 -0.022734  \n",
              "     4        -0.007991 -0.008315 -0.024546  \n",
              "...                 ...       ...       ...  \n",
              "753  45        0.019142 -0.023184 -0.001315  \n",
              "     46        0.007502  0.011425 -0.001580  \n",
              "     47        0.023533 -0.022811 -0.001053  \n",
              "     48        0.000464  0.015894 -0.003321  \n",
              "     49        0.000735 -0.020917 -0.004808  \n",
              "\n",
              "[25200 rows x 250 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-80a9a47b-3606-4c24-b54f-ae8bb5778296\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>timeLag</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>...</th>\n",
              "      <th>241</th>\n",
              "      <th>242</th>\n",
              "      <th>243</th>\n",
              "      <th>244</th>\n",
              "      <th>245</th>\n",
              "      <th>246</th>\n",
              "      <th>247</th>\n",
              "      <th>248</th>\n",
              "      <th>249</th>\n",
              "      <th>250</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>date</th>\n",
              "      <th>stocksID</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">250</th>\n",
              "      <th>0</th>\n",
              "      <td>0.000103</td>\n",
              "      <td>0.012387</td>\n",
              "      <td>0.011243</td>\n",
              "      <td>0.002595</td>\n",
              "      <td>-0.008509</td>\n",
              "      <td>-0.002711</td>\n",
              "      <td>0.008934</td>\n",
              "      <td>0.006571</td>\n",
              "      <td>-0.018546</td>\n",
              "      <td>-0.008353</td>\n",
              "      <td>...</td>\n",
              "      <td>0.009119</td>\n",
              "      <td>-0.008451</td>\n",
              "      <td>0.007120</td>\n",
              "      <td>-0.011745</td>\n",
              "      <td>0.009092</td>\n",
              "      <td>-0.005110</td>\n",
              "      <td>-0.016676</td>\n",
              "      <td>-0.010776</td>\n",
              "      <td>-0.013002</td>\n",
              "      <td>-0.018647</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-0.000982</td>\n",
              "      <td>0.003932</td>\n",
              "      <td>0.000050</td>\n",
              "      <td>0.001616</td>\n",
              "      <td>-0.003902</td>\n",
              "      <td>-0.001686</td>\n",
              "      <td>0.008810</td>\n",
              "      <td>0.001585</td>\n",
              "      <td>-0.000745</td>\n",
              "      <td>-0.002155</td>\n",
              "      <td>...</td>\n",
              "      <td>0.001664</td>\n",
              "      <td>-0.002747</td>\n",
              "      <td>0.009994</td>\n",
              "      <td>-0.001293</td>\n",
              "      <td>0.012912</td>\n",
              "      <td>-0.004055</td>\n",
              "      <td>-0.006820</td>\n",
              "      <td>0.012173</td>\n",
              "      <td>-0.022280</td>\n",
              "      <td>-0.008254</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.009301</td>\n",
              "      <td>0.003914</td>\n",
              "      <td>0.004995</td>\n",
              "      <td>0.001539</td>\n",
              "      <td>0.001452</td>\n",
              "      <td>0.002809</td>\n",
              "      <td>0.005177</td>\n",
              "      <td>-0.006942</td>\n",
              "      <td>-0.013340</td>\n",
              "      <td>-0.008071</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007416</td>\n",
              "      <td>0.001600</td>\n",
              "      <td>0.007640</td>\n",
              "      <td>-0.000637</td>\n",
              "      <td>-0.001353</td>\n",
              "      <td>-0.009522</td>\n",
              "      <td>-0.003425</td>\n",
              "      <td>-0.006044</td>\n",
              "      <td>-0.013629</td>\n",
              "      <td>-0.008404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.006515</td>\n",
              "      <td>-0.006553</td>\n",
              "      <td>0.009464</td>\n",
              "      <td>0.005204</td>\n",
              "      <td>0.004227</td>\n",
              "      <td>-0.005438</td>\n",
              "      <td>0.008861</td>\n",
              "      <td>0.004025</td>\n",
              "      <td>-0.012432</td>\n",
              "      <td>-0.006100</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003807</td>\n",
              "      <td>-0.010636</td>\n",
              "      <td>0.012446</td>\n",
              "      <td>-0.011980</td>\n",
              "      <td>0.002485</td>\n",
              "      <td>-0.017981</td>\n",
              "      <td>-0.010899</td>\n",
              "      <td>-0.008568</td>\n",
              "      <td>-0.006981</td>\n",
              "      <td>-0.022734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-0.006223</td>\n",
              "      <td>0.005415</td>\n",
              "      <td>0.014643</td>\n",
              "      <td>0.005195</td>\n",
              "      <td>0.004489</td>\n",
              "      <td>0.002695</td>\n",
              "      <td>0.007609</td>\n",
              "      <td>0.011437</td>\n",
              "      <td>-0.004804</td>\n",
              "      <td>0.039274</td>\n",
              "      <td>...</td>\n",
              "      <td>0.014404</td>\n",
              "      <td>-0.005255</td>\n",
              "      <td>-0.008182</td>\n",
              "      <td>-0.004614</td>\n",
              "      <td>0.007082</td>\n",
              "      <td>0.007872</td>\n",
              "      <td>-0.003515</td>\n",
              "      <td>-0.007991</td>\n",
              "      <td>-0.008315</td>\n",
              "      <td>-0.024546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th rowspan=\"5\" valign=\"top\">753</th>\n",
              "      <th>45</th>\n",
              "      <td>0.009786</td>\n",
              "      <td>-0.001861</td>\n",
              "      <td>0.012294</td>\n",
              "      <td>-0.023981</td>\n",
              "      <td>0.004069</td>\n",
              "      <td>0.000148</td>\n",
              "      <td>-0.062300</td>\n",
              "      <td>0.040002</td>\n",
              "      <td>-0.003475</td>\n",
              "      <td>-0.016284</td>\n",
              "      <td>...</td>\n",
              "      <td>0.003808</td>\n",
              "      <td>-0.003027</td>\n",
              "      <td>0.002522</td>\n",
              "      <td>-0.006594</td>\n",
              "      <td>-0.000489</td>\n",
              "      <td>0.054751</td>\n",
              "      <td>-0.012180</td>\n",
              "      <td>0.019142</td>\n",
              "      <td>-0.023184</td>\n",
              "      <td>-0.001315</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>-0.008842</td>\n",
              "      <td>0.003698</td>\n",
              "      <td>0.005138</td>\n",
              "      <td>-0.004295</td>\n",
              "      <td>-0.010509</td>\n",
              "      <td>0.010230</td>\n",
              "      <td>0.006846</td>\n",
              "      <td>0.017514</td>\n",
              "      <td>-0.010796</td>\n",
              "      <td>-0.026356</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.012077</td>\n",
              "      <td>-0.002215</td>\n",
              "      <td>0.027569</td>\n",
              "      <td>0.021476</td>\n",
              "      <td>0.003874</td>\n",
              "      <td>-0.001690</td>\n",
              "      <td>0.012346</td>\n",
              "      <td>0.007502</td>\n",
              "      <td>0.011425</td>\n",
              "      <td>-0.001580</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>-0.008607</td>\n",
              "      <td>0.006122</td>\n",
              "      <td>-0.007828</td>\n",
              "      <td>-0.008224</td>\n",
              "      <td>0.011357</td>\n",
              "      <td>-0.012855</td>\n",
              "      <td>0.000346</td>\n",
              "      <td>-0.016681</td>\n",
              "      <td>0.008247</td>\n",
              "      <td>-0.002723</td>\n",
              "      <td>...</td>\n",
              "      <td>0.007291</td>\n",
              "      <td>0.000369</td>\n",
              "      <td>0.000962</td>\n",
              "      <td>-0.005902</td>\n",
              "      <td>0.001067</td>\n",
              "      <td>0.013055</td>\n",
              "      <td>0.015432</td>\n",
              "      <td>0.023533</td>\n",
              "      <td>-0.022811</td>\n",
              "      <td>-0.001053</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>-0.007519</td>\n",
              "      <td>0.001956</td>\n",
              "      <td>0.001903</td>\n",
              "      <td>0.001535</td>\n",
              "      <td>0.000695</td>\n",
              "      <td>0.004107</td>\n",
              "      <td>-0.011879</td>\n",
              "      <td>0.000526</td>\n",
              "      <td>0.003178</td>\n",
              "      <td>-0.010654</td>\n",
              "      <td>...</td>\n",
              "      <td>0.010960</td>\n",
              "      <td>-0.012003</td>\n",
              "      <td>-0.001969</td>\n",
              "      <td>0.030976</td>\n",
              "      <td>-0.000712</td>\n",
              "      <td>0.009795</td>\n",
              "      <td>-0.006842</td>\n",
              "      <td>0.000464</td>\n",
              "      <td>0.015894</td>\n",
              "      <td>-0.003321</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>-0.002816</td>\n",
              "      <td>-0.002696</td>\n",
              "      <td>-0.007145</td>\n",
              "      <td>-0.001814</td>\n",
              "      <td>0.004331</td>\n",
              "      <td>0.005457</td>\n",
              "      <td>0.000633</td>\n",
              "      <td>-0.005819</td>\n",
              "      <td>0.007592</td>\n",
              "      <td>-0.002003</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.024003</td>\n",
              "      <td>0.001416</td>\n",
              "      <td>0.003348</td>\n",
              "      <td>-0.003685</td>\n",
              "      <td>-0.002267</td>\n",
              "      <td>-0.006733</td>\n",
              "      <td>0.000575</td>\n",
              "      <td>0.000735</td>\n",
              "      <td>-0.020917</td>\n",
              "      <td>-0.004808</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>25200 rows × 250 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-80a9a47b-3606-4c24-b54f-ae8bb5778296')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-80a9a47b-3606-4c24-b54f-ae8bb5778296 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-80a9a47b-3606-4c24-b54f-ae8bb5778296');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iR3y2022gMFd"
      },
      "source": [
        "# Function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "GrVH115cgMFf"
      },
      "outputs": [],
      "source": [
        "def fitBeta(A):\n",
        "    X_train_reshape2 = torch.tensor(X_train_reshape.values)\n",
        "    predictors = torch.mm(X_train_reshape2 , A) # the dataframe of the 10 factors created from A with the (date, stock) in index\n",
        "\n",
        "    targets = Y_train.T.stack()\n",
        "    targets = torch.tensor(targets.values)\n",
        "    targets = targets[:,None]\n",
        "\n",
        "    beta = torch.linalg.inv(torch.mm(predictors.T, predictors))\n",
        "    beta = torch.mm(beta, predictors.T)\n",
        "    beta = torch.mm(beta, targets)\n",
        "    \n",
        "\n",
        "    \n",
        "    return beta\n",
        "\n",
        "def metric(df_y_true, df_y_pred):\n",
        "    \"\"\" Compute metric. \"\"\"\n",
        "    if df_y_pred is None:  # If the y_pred has only zeroes, the metric is set to -1.\n",
        "        return -1.0\n",
        "    \n",
        "    y_true = df_y_true.T\n",
        "    y_pred = df_y_pred.T\n",
        "    \n",
        "    y_true = y_true.div(y_true.pow(2.0).sum(1).pow(0.5), 0)\n",
        "    y_pred = y_pred.div(y_pred.pow(2.0).sum(1).pow(0.5), 0)\n",
        "\n",
        "    mean_overlap = (y_true * y_pred).sum(1).mean()\n",
        "\n",
        "    return mean_overlap   \n",
        "\n",
        "def metric_train(X, beta): \n",
        "    \n",
        "    X_train_reshape2 = torch.tensor(X_train_reshape.values)\n",
        "    beta = beta.reshape(10,1)\n",
        "    Ypred = torch.mm(X_train_reshape2, X)\n",
        "    Ypred = torch.mm(Ypred, beta)\n",
        "    Ypred = Ypred.reshape(504,50).T \n",
        "    Ytrue = torch.tensor(Y_train.values)\n",
        "    \n",
        "    for k in range(504):\n",
        "        Ytrue[:,k] = Ytrue[:,k].clone()/torch.linalg.norm(Ytrue[:,k].clone())\n",
        "\n",
        "        Ypred[:,k] = Ypred[:,k].clone()/torch.linalg.norm(Ypred[:,k].clone())\n",
        "\n",
        "    \n",
        "    meanOverlap = torch.mean(torch.sum(Ytrue*Ypred,dim =  0))\n",
        "\n",
        "    return 0.2-meanOverlap\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_zA8yOPgMFg"
      },
      "source": [
        "# Function Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "ow4_0GvEgMFh"
      },
      "outputs": [],
      "source": [
        "def transform_submission_to_ypred(df_A,df_beta, x_test, y_test):\n",
        "    \"\"\" Transform submission output (A, beta) into predicted returns S_t.\"\"\"\n",
        "    df_A = df_A.to_numpy()\n",
        "    df_beta = df_beta.to_numpy()\n",
        "    \n",
        "    A = df_A.reshape((250, 10))\n",
        "    beta = df_beta.reshape(10)\n",
        "\n",
        "    E = pd.DataFrame(A.T @ A - np.eye(10)).abs()  \n",
        "\n",
        "    # check orthogonality of A\n",
        "    if any(E.unstack() > 1e-6): \n",
        "        return None\n",
        "\n",
        "    x_test = x_test.T\n",
        "    y_test = y_test.T\n",
        "\n",
        "    x_test = x_test[y_test.columns]\n",
        "\n",
        "    x_test_reshape = pd.concat([x_test.shift(i+1).stack(dropna=False) for i in range(250)], 1).dropna()\n",
        "    y_pred = (x_test_reshape @ A @ beta).unstack()\n",
        "\n",
        "    return y_pred.T\n",
        "\n",
        "def parametersTransform(A, beta, D=250, F=10):\n",
        "    \n",
        "    if A.shape != (D, F):\n",
        "        print('A has not the good shape')\n",
        "        return\n",
        "    \n",
        "    if beta.shape[0] != F:\n",
        "        print('beta has not the good shape')\n",
        "        return        \n",
        "    \n",
        "    output = np.hstack( (np.hstack([A.T, beta.reshape((F, 1))])).T )\n",
        "    \n",
        "    return output\n",
        "\n",
        "def fitBeta_df(A):\n",
        "    predictors = X_train_reshape @ A # the dataframe of the 10 factors created from A with the (date, stock) in index\n",
        "    targets = Y_train.T.stack()\n",
        "    beta = np.linalg.inv(predictors.T @ predictors) @ predictors.T @ targets\n",
        "    \n",
        "    return beta.to_numpy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-n-szhvgMFi"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "piCLEodJgMFi"
      },
      "outputs": [],
      "source": [
        "torch.cuda.is_available()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8TDzCTM-gMFj"
      },
      "source": [
        "## First model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpplDp8qgMFl"
      },
      "outputs": [],
      "source": [
        "class descente():\n",
        "    def __init__(self):\n",
        "        super(descente, self).__init__()\n",
        "        #self.A = torch.tensor(A_QRT, requires_grad = True)\n",
        "        self.A = torch.rand((250,10), requires_grad = True)\n",
        "\n",
        "    \n",
        "    def parameters(self):\n",
        "      return([self.A])\n",
        "\n",
        "    def forward(self):\n",
        "        return torch.linalg.qr(self.A, mode='reduced')[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "clExK7ZBgMFm"
      },
      "outputs": [],
      "source": [
        "model = descente()\n",
        "\n",
        "A = torch.zeros((250,10), requires_grad = True)\n",
        "beta =  fitBeta(A)\n",
        "\n",
        "n_epochs = 1000\n",
        "lr = 0.5\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YFRm8R9wgMFm"
      },
      "outputs": [],
      "source": [
        "total_loss = 0.0\n",
        "min_loss = 0.2\n",
        "Mat_fin = torch.rand(250,10)\n",
        "Loss_mat = []\n",
        "Loss_test = []\n",
        "for j in range(n_epochs):\n",
        "  \n",
        "  Mat = model.forward().double()\n",
        "  Mat.to(device)\n",
        "\n",
        "  beta  = Mat.clone().detach()\n",
        "  beta.to(device)\n",
        "  beta =  fitBeta(beta)\n",
        "  \n",
        "\n",
        "  #loss = metric_train(Mat, beta  )\n",
        "  loss =  metric_train(Mat, beta)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if loss.item() < min_loss:\n",
        "    min_loss = loss.item()\n",
        "    Mat_fin = Mat.clone().detach().numpy()\n",
        "\n",
        "\n",
        " \n",
        "  \n",
        "  total_loss += loss.item()\n",
        "  if j >0:\n",
        "    Loss_test.append(metric_train(Mat.detach(), beta))\n",
        "    Loss_mat.append(loss.item())\n",
        "\n",
        "  if j%100 ==0:\n",
        "    abscisse = np.linspace(1,len(Loss_mat), len(Loss_mat))\n",
        "    plt.plot(abscisse, Loss_mat)\n",
        "    plt.plot(abscisse, Loss_test)\n",
        "\n",
        "    plt.show()\n",
        "    #Loss_mat = []\n",
        "    print('At epochs '+str(j+1)+' : '+str(total_loss/(j+1)))\n",
        "    print('min_loss : '+str(min_loss))\n",
        "    Mat_fin = pd.DataFrame(Mat_fin)\n",
        "    Mat_fin.to_csv('./Challenge/random'+str(j))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iz5P7CZ-gMFn"
      },
      "source": [
        "# Second model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MJ2qIVqrgMFo"
      },
      "outputs": [],
      "source": [
        "class descente():\n",
        "    def __init__(self):\n",
        "        super(descente, self).__init__()\n",
        "        #self.A = torch.tensor(A_QRT, requires_grad = True)\n",
        "        self.A = torch.rand((250,10), requires_grad = True)\n",
        "        self.B = torch.rand((10), requires_grad = True)\n",
        "\n",
        "    def parameters(self):\n",
        "      return([self.A, self.B])\n",
        "\n",
        "    def forward(self):\n",
        "        return torch.linalg.qr(self.A, mode='reduced')[0], self.B"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jJi1PJtXgMFo"
      },
      "outputs": [],
      "source": [
        "model = descente()\n",
        "n_epochs = 1000\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr= 0.005)\n",
        "total_loss = 0.0\n",
        "min_loss = 0.2\n",
        "Mat_fin = torch.rand(250,10)\n",
        "beta_fin = torch.rand(10)\n",
        "Loss_mat = []\n",
        "for j in range(n_epochs):\n",
        "  \n",
        "  Mat, beta = model.forward()\n",
        "  Mat.to(device)\n",
        "  Mat = Mat.double()\n",
        "  #beta  = Mat.clone().detach()\n",
        "  beta.to(device)\n",
        "  beta = beta.double()\n",
        "  \n",
        "\n",
        "\n",
        "  loss =  metric_train(Mat, beta)\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "\n",
        "  if loss.item() < min_loss:\n",
        "    min_loss = loss.item()\n",
        "    Mat_fin = Mat.clone().detach().numpy()\n",
        "    beta_fin = beta.clone().detach().numpy()\n",
        "\n",
        "\n",
        " \n",
        "    \n",
        "  total_loss += loss.item()\n",
        "  if j >0:\n",
        "\n",
        "    Loss_mat.append(loss.item())\n",
        "\n",
        "  if j%50 ==0:\n",
        "    abscisse = np.linspace(1,len(Loss_mat), len(Loss_mat))\n",
        "    plt.plot(abscisse, Loss_mat)\n",
        "    plt.show()\n",
        "    #Loss_mat = []\n",
        "    print('At epochs '+str(j+1)+' : '+str(total_loss/(j+1)))\n",
        "    print('min_loss : '+str(min_loss))\n",
        "    Mat_fin = pd.DataFrame(Mat_fin)\n",
        "    Mat_fin.to_csv('./Challenge/A'+str(j))\n",
        "\n",
        "    beta_fin = pd.DataFrame(beta_fin)\n",
        "    beta_fin.to_csv('./Challenge/beta'+str(j))\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9oyg426TgMFo"
      },
      "source": [
        "# Submission "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kN4qq6pWgMFp"
      },
      "outputs": [],
      "source": [
        "pathA = ''\n",
        "pathOutput = ''\n",
        "\n",
        "A = pd.read_csv('./Challenge/'+pathA, index_col=0, sep=',').to_numpy()\n",
        "#beta = pd.read_csv(PATH_GC+'/Challenge/beta1050', index_col=0, sep=',').to_numpy()\n",
        "\n",
        "beta = fitBeta_df(A)\n",
        "output = parametersTransform(A, beta)\n",
        "pd.DataFrame(output).to_csv('./Challenge/'+pathOutput+'.csv')"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}